# LLM Provider Configuration
# Options: anthropic, ollama
LLM_PROVIDER=anthropic

# Anthropic API Configuration (required if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your-api-key-here
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# Open API Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4o-mini

# Ollama Configuration (required if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gpt-oss:20b

# Application Settings
APP_ENV=development
DEBUG=true

# Server Settings
HOST=0.0.0.0
PORT=8000

# Data Storage Paths
DATA_DIR=./data
MEMORIES_DIR=./data/memories
SESSIONS_DIR=./data/sessions

# LLM Settings (for Anthropic)
MAX_TOKENS=4096
TEMPERATURE=0.7
